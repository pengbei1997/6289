{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S99NYaWpFhuD"
      },
      "source": [
        "from numpy import nan\n",
        "from numpy import isnan\n",
        "from pandas import read_csv\n",
        "from pandas import to_numeric\n",
        " \n",
        "# fill missing values with a value at the same time one day ago\n",
        "def fill_missing(values):\n",
        "\tone_day = 60 * 24\n",
        "\tfor row in range(values.shape[0]):\n",
        "\t\tfor col in range(values.shape[1]):\n",
        "\t\t\tif isnan(values[row, col]):\n",
        "\t\t\t\tvalues[row, col] = values[row - one_day, col]\n",
        " \n",
        "# load all data\n",
        "dataset = read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
        "# mark all missing values\n",
        "dataset.replace('?', nan, inplace=True)\n",
        "# make dataset numeric\n",
        "dataset = dataset.astype('float32')\n",
        "# fill missing\n",
        "fill_missing(dataset.values)\n",
        "# add a column for for the remainder of sub metering\n",
        "values = dataset.values\n",
        "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n",
        "# save updated dataset\n",
        "dataset.to_csv('household_power_consumption.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZDy9FoPcb5i",
        "outputId": "19ec4b9f-39b3-4b7e-eb19-a2498ef66c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# resample minute data to total for each day\n",
        "from pandas import read_csv\n",
        "# load the new file\n",
        "dataset = read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
        "# resample data to daily\n",
        "daily_groups = dataset.resample('D')\n",
        "daily_data = daily_groups.sum()\n",
        "# summarize\n",
        "print(daily_data.shape)\n",
        "print(daily_data.head())\n",
        "# save\n",
        "daily_data.to_csv('household_power_consumption_days.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24, 8)\n",
            "            Global_active_power  ...  sub_metering_4\n",
            "datetime                         ...                \n",
            "2006-12-16             1209.176  ...    14680.933319\n",
            "2006-12-17             3390.460  ...    36946.666732\n",
            "2006-12-18             2203.826  ...    19028.433281\n",
            "2006-12-19             1666.194  ...    13131.900043\n",
            "2006-12-20             2225.748  ...    20384.800011\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjVkwb2AcpMy"
      },
      "source": [
        "\n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-TUV3F6cxQ3",
        "outputId": "9fbabcf1-1f04-437b-9bc6-44d21bb6b7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "\n",
        "# split into standard weeks\n",
        "from numpy import split\n",
        "from numpy import array\n",
        "from pandas import read_csv\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def split_dataset(data):\n",
        "\t# split into standard weeks\n",
        "\ttrain = data[1:-328], test = data[-328:-6]\n",
        "\t# restructure into windows of weekly data\n",
        "  train = array(split(train, len(train)/7)\n",
        "\ttest = array(split(test, len(test)/7))\n",
        "\treturn train, test\n",
        "\n",
        "# load the new file\n",
        "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
        "train, test = split_dataset(dataset.values)\n",
        "# validate train data\n",
        "print(train.shape)\n",
        "print(train[0, 0, 0], train[-1, -1, 0])\n",
        "# validate test\n",
        "print(test.shape)\n",
        "print(test[0, 0, 0], test[-1, -1, 0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-9e5fc2f1b104>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    train = array(split(train, len(train)/7)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKeGfrsIc2bx"
      },
      "source": [
        "\n",
        "# evaluate a single model\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\treturn score, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdALDf1c-XL"
      },
      "source": [
        "\n",
        "# summarize scores\n",
        "def summarize_scores(name, score, scores):\n",
        "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovuukikwdDET",
        "outputId": "871f9503-4b99-4084-bdb0-387cc89fcd9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "\n",
        "# convert history into inputs and outputs\n",
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tx_input = data[in_start:in_end, 0]\n",
        "\t\t\tx_input = x_input.reshape((len(x_input), 1))\n",
        "\t\t\tX.append(x_input)\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-ace587c10290>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    return array(X), array(y\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyoPj70_da7U"
      },
      "source": [
        "\n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 0, 70, 16\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bYKCfYNdg9d"
      },
      "source": [
        "\n",
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, 0]\n",
        "\t# reshape into [1, n_input, 1]\n",
        "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8esP8-d7dwWC"
      },
      "source": [
        "from math import sqrt\n",
        "from numpy import split\n",
        "from numpy import array\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        " \n",
        "# split a univariate dataset into train/test sets\n",
        "def split_dataset(data):\n",
        "\t# split into standard weeks\n",
        "\ttrain, test = data[1:-328], data[-328:-6]\n",
        "\t# restructure into windows of weekly data\n",
        "\ttrain = array(split(train, len(train)/7))\n",
        "\ttest = array(split(test, len(test)/7))\n",
        "\treturn train, test\n",
        " \n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores\n",
        " \n",
        "# summarize scores\n",
        "def summarize_scores(name, score, scores):\n",
        "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
        " \n",
        "# convert history into inputs and outputs\n",
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tx_input = data[in_start:in_end, 0]\n",
        "\t\t\tx_input = x_input.reshape((len(x_input), 1))\n",
        "\t\t\tX.append(x_input)\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 0, 70, 16\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model\n",
        " \n",
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, 0]\n",
        "\t# reshape into [1, n_input, 1]\n",
        "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat\n",
        " \n",
        "# evaluate a single model\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\treturn score, scores\n",
        " \n",
        "# load the new file\n",
        "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
        "# split into train and test\n",
        "train, test = split_dataset(dataset.values)\n",
        "# evaluate model and get scores\n",
        "n_input = 7\n",
        "score, scores = evaluate_model(train, test, n_input)\n",
        "# summarize scores\n",
        "summarize_scores('lstm', score, scores)\n",
        "# plot scores\n",
        "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
        "pyplot.plot(days, scores, marker='o', label='lstm')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F01qExbVe7RJ"
      },
      "source": [
        "\n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 0, 20, 16\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# reshape output into [samples, timesteps, features]\n",
        "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(RepeatVector(n_outputs))\n",
        "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dense(1)))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spMiL0c7fVzO"
      },
      "source": [
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tX.append(data[in_start:in_end, :])\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53H6RD2gfbUw"
      },
      "source": [
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, :]\n",
        "\t# reshape into [1, n_input, n]\n",
        "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Uce0olfigA"
      },
      "source": [
        " #evaluate a single model\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\treturn score, scores\n",
        " \n",
        "# load the new file\n",
        "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
        "# split into train and test\n",
        "train, test = split_dataset(dataset.values)\n",
        "# evaluate model and get scores\n",
        "n_input = 14\n",
        "score, scores = evaluate_model(train, test, n_input)\n",
        "# summarize scores\n",
        "summarize_scores('lstm', score, scores)\n",
        "# plot scores\n",
        "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
        "pyplot.plot(days, scores, marker='o', label='lstm')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1wC3KH3f0KC"
      },
      "source": [
        "\n",
        "\n",
        "# multivariate multi-step encoder-decoder lstm\n",
        "from math import sqrt\n",
        "from numpy import split\n",
        "from numpy import array\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        " \n",
        "# split a univariate dataset into train/test sets\n",
        "def split_dataset(data):\n",
        "\t# split into standard weeks\n",
        "\ttrain, test = data[1:-328], data[-328:-6]\n",
        "\t# restructure into windows of weekly data\n",
        "\ttrain = array(split(train, len(train)/7))\n",
        "\ttest = array(split(test, len(test)/7))\n",
        "\treturn train, test\n",
        " \n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores\n",
        " \n",
        "# summarize scores\n",
        "def summarize_scores(name, score, scores):\n",
        "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
        " \n",
        "# convert history into inputs and outputs\n",
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tX.append(data[in_start:in_end, :])\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 0, 50, 16\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# reshape output into [samples, timesteps, features]\n",
        "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(RepeatVector(n_outputs))\n",
        "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dense(1)))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model\n",
        " \n",
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, :]\n",
        "\t# reshape into [1, n_input, n]\n",
        "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat\n",
        " \n",
        "# evaluate a single model\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\treturn score, scores\n",
        " \n",
        "# load the new file\n",
        "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
        "# split into train and test\n",
        "train, test = split_dataset(dataset.values)\n",
        "# evaluate model and get scores\n",
        "n_input = 14\n",
        "score, scores = evaluate_model(train, test, n_input)\n",
        "# summarize scores\n",
        "summarize_scores('lstm', score, scores)\n",
        "# plot scores\n",
        "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
        "pyplot.plot(days, scores, marker='o', label='lstm')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}